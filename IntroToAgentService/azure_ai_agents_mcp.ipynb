{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8164f68d",
   "metadata": {},
   "source": [
    "# Azure AI Agents MCP Example\n",
    "\n",
    "This notebook demonstrates how to create and interact with an Azure AI Foundry Agent using the Azure AI Projects SDK. Supported regions at time of writing: westus, westus2, uaenorth, southindia and switzerlandnorth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71df8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be59f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageTextContent, ListSortOrder\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Initialize the AIProjectClient\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT2\"),\n",
    "    credential=DefaultAzureCredential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ab0e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_bkaLGyf7y6cf3jjID84QMPGe\n"
     ]
    }
   ],
   "source": [
    "# Create an agent with MCP tool support\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "    name=\"my-mcp-agent\",\n",
    "    instructions=(\n",
    "        \"You are a helpful assistant. Use the tools provided \"\n",
    "        \"to answer the user's questions. Be sure to cite your sources.\"\n",
    "    ),\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"MicrosoftDocs\",\n",
    "        \"server_url\": \"https://learn.microsoft.com/api/mcp\",\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    tool_resources=None\n",
    ")\n",
    "print(f\"Created agent, agent ID: {agent.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85034f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, thread ID: thread_jFQIyZpteIvNNY7LAnzqbW8L\n",
      "Created message, message ID: msg_FmncGTRCNBm8tepFfeziuzUr\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation thread and send a user message\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Does Azure AI Foundry Agent Service support Model Context Protocol as a tool?\"\n",
    ")\n",
    "print(f\"Created message, message ID: {message.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "333d7a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.IN_PROGRESS\n",
      "Run status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# Run the agent and poll for completion\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# Poll the run status\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run error: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308cb846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run step: step_ORIdBzvZhjoEKwDfwKrXFi6r, status: RunStepStatus.COMPLETED, type: RunStepType.MESSAGE_CREATION\n",
      "Run step: step_MuRVt2gKixRMbxpn7grbjE7O, status: RunStepStatus.COMPLETED, type: RunStepType.TOOL_CALLS\n",
      "Tool call details:\n",
      "{\n",
      "  \"id\": \"call_Cdrk5Xya8FE2WTC8h3tF5Ynk\",\n",
      "  \"type\": \"mcp\",\n",
      "  \"arguments\": \"{\\\"question\\\":\\\"Does Azure AI Foundry Agent Service support Model Context Protocol as a tool?\\\"}\",\n",
      "  \"name\": \"microsoft_docs_search\",\n",
      "  \"output\": \"[{\\\"title\\\": \\\"What's new in Azure AI Foundry Agent Service\\\", \\\"content\\\": \\\"# What's new in Azure AI Foundry Agent Service\\\\nThis article provides a summary of the latest releases and major documentation updates for Azure AI Foundry Agent Service.\\\\n## June 2025\\\\n### Model Context Protocol (MCP) tool\\\\nYou can new extend the capabilities of your agents by connecting them to tools hosted on remote [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) servers by using the [MCP tool](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol).\\\\n## May 2025\\\\n### Azure AI Foundry Agent Service GA\\\\nThe Azure AI Foundry Agent Service is now Generally Available (GA). Along with this milestone, the service offers the following feature updates:\\\\n### Agent catalog\\\\nThe [agent catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/agent-catalog) helps streamline your agent deployment with prebuilt, task-specific agent code samples across a variety of domains such as translation, sales prep, computer use, and more.\\\\n### AI Foundry Visual Studio Code extension\\\\nThe [AI Foundry Visual Studio Code extension](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/vs-code-agents?context=/azure/ai-services/agents/context/context) is now available with the ability to perform a variety of AI Foundry actions, such as deploying and configure agents natively.\\\\n### Connected agents\\\\n[Connected agents](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/connected-agents) allow you to create task-specific agents that can interact seamlessly with a primary agent. This feature enables you to build multi-agent systems without the need for external orchestrators.\\\\n### Trace agents\\\\nDebug and monitor your agents by [tracing agent threads](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/tracing) to clearly see the inputs and outputs of each primitive involved in a particular agent run, in the order in which they were invoked.\\\\n### Trigger agents using Azure Logic Apps\\\\n[Automatically invoke](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/triggers) your AI agent when an event occurs, such as receiving a new email, or getting a new customer ticket so that your AI agent can immediately respond to the new event without manual invocation.\\\\n### New agent tools\\\\nThis release brings a number of new tools to extend agents' capabilities:\\\\n1. **Bing Custom Search tool** - Determine which websites will be used to ground your agents with.\\\\n2. **Morningstar tool** - Leverage Morningstar, a prominent investment research company, as a data source for your agent.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/whats-new\\\"}, {\\\"title\\\": \\\"What are tools in Azure AI Foundry Agent Service?\\\", \\\"content\\\": \\\"# What are tools in Azure AI Foundry Agent Service?\\\\nTo empower your AI agent with grounded data or the capability to take actions and automating workflows, the Foundry Agent service provides a wide range of built-in tools, such as Grounding with Bing Search, Azure AI Search, Azure Logic Apps, as well as third-party parter tools, such as Tripadvisor. This page is designed to provide an overview of tools provided in the Foundry Agent Service.\\\\n## Knowledge tools\\\\nTo keep your AI agent informed with richer context from various data sources. The Foundry Agent Service has covered a wide range of data types:\\\\n1. **private data**: Azure AI Search, File Search, Microsoft Fabric, and more\\\\n2. **public web data**: Grounding with Bing Search\\\\n3. **licensed data**: Tripadvisor, Morningstar\\\\n4. **unstructured data**: Azure AI Search, File Search\\\\n5. **structured data**: Microsoft Fabric and more\\\\n## Action tools\\\\nTo streamline workflows with your AI agent with capabilities to take actions. The Foundry Agent Service provides different action tools for you with different level of flexibility, control, and ease of integration:\\\\n1. **Azure Logic Apps**: Low-code / no-code solution to add a workflow to your AI Agent\\\\n2. **OpenAPI Spec tool**: Bring an existing OpenAPI specification of a service API you want to add to your AI agent, with no or minor changes.\\\\n3. **MCP tool**: Bring an existing Model Context Protocol (MCP) endpoint that you want to add to your AI agent.\\\\n4. **Function calling**: Write your own custom, stateless functions to define the expected behaviors.\\\\n5. **Azure Functions**: Write and manage your own custom, stateful functions.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/overview\\\"}, {\\\"title\\\": \\\"Connect to Model Context Protocol (MCP) Servers (Preview)\\\", \\\"content\\\": \\\"# Connect to Model Context Protocol (MCP) Servers (Preview)\\\\nYou can extend the capabilities of your Foundry Agent by connecting it to tools hosted on remote Model Context Protocol (MCP) servers (bring your own MCP server endpoint). These servers are maintained by developers and organizations and expose tools that can be accessed by MCP-compatible clients, such as the Foundry Agent service.\\\\n[Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) is an open standard that defines how applications provide tools and contextual data to large language models (LLMs). It enables consistent, scalable integration of external tools into model workflows.\\\\nImportant\\\\n1. Your use of connected non-Microsoft services is subject to the terms between you and the service provider. By connecting to a non-Microsoft service, some of your data, such as prompt content, is passed to the non-Microsoft service, and/or your application might receive data from the non-Microsoft service. You are responsible for your use (and any charges associated with your use) of non-Microsoft services and data.\\\\n2. The remote MCP servers you decide to use with this MCP tool were created by third parties, not Microsoft, and have not been tested or verified by Microsoft. Microsoft has no responsibility to you or others in relation to your use of any remote MCP servers. We recommend carefully reviewing and tracking what MCP servers you add to Foundry Agent service and relying on servers hosted by trusted service providers themselves rather than proxies. This MCP tool also allows you to pass custom headers such as authentication keys or schema as might be needed by a remote MCP server. We recommend reviewing all data being shared with remote MCP servers and optionally logging it for auditing purposes. Be cognizant of non-Microsoft practices for retention and location of data.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol\\\"}, {\\\"title\\\": \\\"What are tools in Azure AI Foundry Agent Service?\\\", \\\"content\\\": \\\"# What are tools in Azure AI Foundry Agent Service?\\\\n## Built-in tools\\\\nThe Foundry Agent Service provides the following built-in tools. You can use them with the REST API, SDK, and Azure AI Foundry portal.\\\\n| Tool | Description| \\\\n|  --- | ---  |\\\\n| [Azure AI Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/azure-ai-search) | Use an existing Azure AI Search index to ground agents with data in the index, and chat with your data. |\\\\n| [Azure Functions](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/azure-functions) | Leverage your Azure Functions to create intelligent, event-driven applications. |\\\\n| [Code Interpreter](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/code-interpreter) | Enable agents to write and run Python code in a sandboxed execution environment. |\\\\n| [File Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/file-search) | Augment agents with knowledge from outside its model, such as proprietary product information or documents provided by your users. |\\\\n| [Function calling](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/function-calling) | Describe the structure of functions you create to an agent and have them be called when appropriate during the agent's interactions with users. |\\\\n| [Grounding with Bing Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-grounding) | Enable your agent to use Grounding with Bing Search to access and return information from the internet. |\\\\n| [Grounding with Bing Custom Search (preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-custom-search) | Enhance your Agent response with selected web domains |\\\\n| [Model Context Protocol (preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol) | Give the agent access to tools hosted on an existing MCP endpoint |\\\\n| [Microsoft Fabric (preview)](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/fabric) | Integrate your agent with the [Microsoft Fabric data agent](https://go.microsoft.com/fwlink/?linkid=2312815) to unlock powerful data analysis capabilities. |\\\\n| [OpenAPI 3.0 Specified tool](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/openapi-spec) | Connect your Azure AI Agent to external APIs using functions with an OpenAPI 3.0 specification. |\\\\n\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/overview#built-in-tools\\\"}, {\\\"title\\\": \\\"How to use the Model Context Protocol (MCP) tool\\\", \\\"content\\\": \\\"# How to use the Model Context Protocol (MCP) tool\\\\nUse this article to find step-by-step instructions and code samples for connecting Foundry Agent service with MCP.\\\\nFollow the [REST API Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/quickstart?pivots=rest-api#api-call-information) to set the right values for the environment variables `AGENT_TOKEN`, `AZURE_AI_FOUNDRY_PROJECT_ENDPOINT` and `API_VERSION`.\\\\n## Create an Agent with the MCP tool enabled\\\\nTo make the MCP tool available to your agent, initialize a tool with the server endpoint, server label and more\\\\n## Create a thread\\\\n```bash\\\\ncurl --request POST \\\\\\\\\\\\n  --url $AZURE_AI_FOUNDRY_PROJECT_ENDPOINT/threads?api-version=$API_VERSION \\\\\\\\\\\\n  -H \\\\\\\"Authorization: Bearer $AGENT_TOKEN\\\\\\\" \\\\\\\\\\\\n  -H \\\\\\\"Content-Type: application/json\\\\\\\" \\\\\\\\\\\\n  -d ''\\\\n```\\\\n## Add a user question to the thread\\\\n```bash\\\\ncurl --request POST \\\\\\\\\\\\n  --url $AZURE_AI_FOUNDRY_PROJECT_ENDPOINT/threads/thread_abc123/messages?api-version=$API_VERSION \\\\\\\\\\\\n  -H \\\\\\\"Authorization: Bearer $AGENT_TOKEN\\\\\\\" \\\\\\\\\\\\n  -H \\\\\\\"Content-Type: application/json\\\\\\\" \\\\\\\\\\\\n  -d '{\\\\n      \\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"<user input related to the MCP server you connect>\\\\\\\"\\\\n    }'\\\\n```\\\\n## Create a run and check the output\\\\nCreate a run to pass headers for the tool and observe that the model uses the Grounding with Bing Search tool to provide a response to the user's question.\\\\n## Retrieve the status of the run\\\\n```bash\\\\ncurl --request GET \\\\\\\\\\\\n  --url $AZURE_AI_FOUNDRY_PROJECT_ENDPOINT/threads/thread_abc123/runs/run_abc123?api-version=$API_VERSION \\\\\\\\\\\\n  -H \\\\\\\"Authorization: Bearer $AGENT_TOKEN\\\\\\\"\\\\n```\\\\n## Retrieve the agent response\\\\n```bash\\\\ncurl --request GET \\\\\\\\\\\\n  --url $AZURE_AI_FOUNDRY_PROJECT_ENDPOINT/threads/thread_abc123/messages?api-version=$API_VERSION \\\\\\\\\\\\n  -H \\\\\\\"Authorization: Bearer $AGENT_TOKEN\\\\\\\"\\\\n```\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples\\\"}, {\\\"title\\\": \\\"Connect to Model Context Protocol (MCP) Servers (Preview)\\\", \\\"content\\\": \\\"# Connect to Model Context Protocol (MCP) Servers (Preview)\\\\n## How it works\\\\nYou can bring multiple remote MCP servers to Foundry Agent service by adding them as tools. For each tool, you need to provide a unique `server_label` within the same agent and `server_url` that points to the remote MCP server. The MCP tool supports custom headers, allowing you to connect to these servers using the authentication scheme they require or passing other headers required by the MCP server. You can only specify headers by including in `tool_resources` at each run such as API keys, OAuth access tokens, or other credentials directly in your request. The most commonly used header is the authorization header. For more information on using MCP, see:\\\\n1. [Security best practices](https://modelcontextprotocol.io/specification/draft/basic/security_best_practices)\\\\n2. [Understanding and mitigating security risks in MCP implementations](https://techcommunity.microsoft.com/blog/microsoft-security-blog/understanding-and-mitigating-security-risks-in-mcp-implementations/4404667)\\\\nNote\\\\n1. You need to bring a remote MCP server (an existing MCP server endpoint)\\\\n2. With current MCP tool in Foundry Agent, explicit approval is not supported (only `never` is accepted for `require_approval` parameter). Please review carefully what MCP server(s) you added to Foundry Agent service. We recommend reviewing all data being shared with remote MCP servers and optionally logging it for auditing purposes.\\\\n3. Supported regions: `westus`, `westus2`, `uaenorth`, `southindia` and `switzerlandnorth`\\\\n4. The MCP tool supports custom headers for a specific run, allowing you to pass headers as needed by MCP server, such as authentication schema. Headers you pass in will only be available for the current run and will not be persisted.\\\\n## Usage support\\\\n| Azure AI foundry support | Python SDK | C# SDK | JavaScript SDK | REST API | Basic agent setup | Standard agent setup| \\\\n|  --- | --- | --- | --- | --- | --- | ---  |\\\\n| - | - | - | - | \\\\u2714\\\\ufe0f | \\\\u2714\\\\ufe0f | \\\\u2714\\\\ufe0f |\\\\n\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol#how-it-works\\\"}, {\\\"title\\\": \\\"Transparency Note for Azure Agent Service\\\", \\\"content\\\": \\\"# Transparency Note for Azure Agent Service\\\\n## Capabilities\\\\n1. **File Search** (a built-in retrieval-augmented generation (RAG) tool to process and search through private data in Azure AI Search, Azure Blob Storage, and local files)\\\\n2. **Grounding with Bing Search** (a web search tool that uses Bing Search to extract information from the web)\\\\n3. **SharePoint** (built-in tools that connect an organization\\\\u2019s internal documents in SharePoint for grounded responses)\\\\n4. **Fabric Data Agent** (a built-in tool to chat with structured data on Microsoft Fabric using generative AI)\\\\n5. **Bring your licensed data** (a tool that enables grounding using proprietary data accessed using a licensed API key obtained by the developer from the data provider, for example, TripAdvisor)\\\\nAgents simplify secure data access to SharePoint and Fabric AI Skills through on-behalf-of (OBO) authentication, allowing the Agent to access only the SharePoint or Fabric files for which the user has permissions.\\\\n#### Enabling autonomous actions with or without human input through Action Tools\\\\nDevelopers can connect an Agent to external systems, APIs, and services through Action Tools, enabling the Agent to perform tasks and take actions on behalf of users. Action Tools built into Azure AI Agent Service include:\\\\n1. **Code Interpreter** (a tool that can write and run Python code in a secure environment, handle diverse data formats and generate files with data and visuals)\\\\n2. **Azure Logic Apps** (a cloud-based PaaS tool that enables automated workflows using 1,400+ built-in connectors)\\\\n3. **Azure Functions** (a tool that enables an Agent to execute serverless code for synchronous, asynchronous, long-running, and event-driven actions)\\\\n4. **OpenAPI 3.0 specified tools** (a custom function defined with OpenAPI 3.0 specification to connect an Agent to external OpenAPI-based APIs securely)\\\\n5. **Model Context Protocol tools** (a custom service connected via Model Context Protocol through an existing remote MCP server to an Agent).\\\\n#### Orchestrating multi-agent systems\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/agents/transparency-note#capabilities\\\"}, {\\\"title\\\": \\\"Connect to Model Context Protocol (MCP) Servers (Preview)\\\", \\\"content\\\": \\\"# Connect to Model Context Protocol (MCP) Servers (Preview)\\\\n## Setup\\\\n1. Create an Azure AI Foundry Agent by following the steps in the [quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/quickstart).\\\\n2. Find the remote MCP server you want to connect to, such as GitHub MCP Server. Create or update a Foundry Agent with a `mcp` tool with the following information:\\\\n2.1. `server_url`: the url of the MCP server, for example, `https://api.githubcopilot.com/mcp/`\\\\n2.2. `server_label`: a unique identifier of this MCP server to the agent, for example, `github`\\\\n2.3. `require_approval`: only `never` is supported right now\\\\n3. Create a run and pass additional information about the `mcp` tool in `tool_resources` with headers\\\\n3.1. `tool_label`: use the identifier you provided during create/update agent\\\\n3.2. `headers`: pass a set of headers required by the MCP server\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol#setup\\\"}, {\\\"title\\\": \\\"What are tools in Azure AI Foundry Agent Service?\\\", \\\"content\\\": \\\"# What are tools in Azure AI Foundry Agent Service?\\\\n## How does a tool work in the Foundry Agent Service?\\\\nTools are optional capabilities you can add to your AI agent for AI models to decide and pick based on the user query and context. When a user sends a query, the AI model identifies the intent with the context and potentially rewrites the user query. Then the AI model decides which tools to be called for each run. For example, if you add both the Grounding with Bing Search tool and the Azure AI Search tool to your agent and ask \\\\\\\"*what is the weather in Seattle today?*\\\\\\\", the model will identify your intent to ask about real-time information and more likely to invoke the Grounding with Bing Search tool.\\\\nYou can add tools at the agent, thread, or run level. By providing tools at a narrower level, the tool resources will **override** tool resources at a broader level. For example, tool resources at the run level override tool resources at thread level. Currently, you can add multiple tools but you can add **one instance of each** of the following tools: File Search, Azure AI Search, Grounding with Bing Search, Grounding with Bing Custom Search, Microsoft Fabric, and other tools under `knowledge` section.\\\\nWhen a user sends a query to the agent, it will create a [thread, run, and message](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/threads-runs-messages). For each run, the AI model decides what tools to invoke based on the user intent and available tool resources. Based on the tool outputs, the AI model might decide to invoke another tool or call the same tool again to get more context. For example, when you use Grounding with Bing Search tool, you might see multiple Bing Search queries when [tracing a thread](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/tracing). This means the AI model actually calls the Grounding with Bing Search tool multiple times with different queries to get more information. If you want to learn more about what tools are called and how the AI model invokes them, check the run step details.\\\\nThere are various ways to influence how your AI agent invokes tools:\\\\n1. The `tool_choice` parameter: Most deterministic way of controlling which (if any) tool is called by the model. By default, it is set to `auto`, which means the AI model will decide. If you want to **force** the model to call a specific tool, you can provide the specification of this tool, for example\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/overview#how-does-a-tool-work-in-the-foundry-agent-service\\\"}, {\\\"title\\\": \\\"Models supported by Azure AI Foundry Agent Service\\\", \\\"content\\\": \\\"# Models supported by Azure AI Foundry Agent Service\\\\n## Azure AI Foundry models\\\\n### Models with tool-calling\\\\nTo best support agentic scenarios, we recommend using models that support tool-calling. The Azure AI Foundry Agent Service currently supports all agent-compatible models from the Azure AI Foundry model catalog.\\\\nTo use these models, use the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to make a model deployment, then reference the deployment name in your agent. For example:\\\\n`agent = project_client.agents.create_agent( model=\\\\\\\"llama-3\\\\\\\", name=\\\\\\\"my-agent\\\\\\\", instructions=\\\\\\\"You are a helpful agent\\\\\\\")`\\\\nNote\\\\nThis option should only be used for open-source models (for example, Cepstral, Mistral, Llama) and not for OpenAI models, which are natively supported in the service. This option should also only be used for models that support tool-calling.\\\\n### Models without tool-calling\\\\nThough tool-calling support is a core capability for agentic scenarios, we now provide the ability to use models that don\\\\u2019t support tool-calling in our API and SDK. This option can be helpful when you have specific use-cases that don\\\\u2019t require tool-calling.\\\\nThe following steps will allow you to utilize any chat-completion model that is available through a [serverless API](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/model-catalog-overview):\\\\n1. Deploy your desired model through serverless API. Model will show up on your **Models + Endpoints** page.\\\\n2. Click on model name to see model details, where you'll find your model's target URI and key.\\\\n3. Create a new Serverless connection on **Connected Resources** page, using the target URI and key.\\\\nThe model can now be referenced in your code (`Target URI` + `@` + `Model Name`), for example:\\\\n`Model=https://Phi-4-mejco.eastus.models.ai.azure.com/@Phi-4-mejco`\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/model-region-support#azure-ai-foundry-models\\\"}]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect run steps for tool calls\n",
    "run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "for step in run_steps:\n",
    "    print(f\"Run step: {step.id}, status: {step.status}, type: {step.type}\")\n",
    "    if step.type == \"tool_calls\":\n",
    "        print(\"Tool call details:\")\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(json.dumps(tool_call.as_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6311ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageRole.USER: Does Azure AI Foundry Agent Service support Model Context Protocol as a tool?\n",
      "MessageRole.AGENT: Yes, Azure AI Foundry Agent Service supports Model Context Protocol (MCP) as a tool. You can extend the capabilities of your agents by connecting them to tools hosted on remote Model Context Protocol (MCP) servers using the built-in MCP tool. This allows your agent to interact with external tools and APIs via the MCP standard, which is designed for scalable integration of external functions into AI workflows.\n",
      "\n",
      "Key points:\n",
      "- The MCP tool lets you add external MCP server endpoints to your agent, making their functions callable by the agent.\n",
      "- The service supports custom headers (such as authentication tokens) when connecting to MCP servers.\n",
      "- Documentation and step-by-step setup instructions are available to help you enable the MCP tool for your agents.\n",
      "\n",
      "References:\n",
      "- What's new in Azure AI Foundry Agent Service (June 2025 includes MCP tool): [Learn more](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/whats-new)\n",
      "- Tool overview and usage: [Azure AI Foundry Agent Service Tools](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/overview)\n",
      "- Model Context Protocol tool setup and samples: [Connect to MCP servers](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)\n",
      "\n",
      "In summary, Azure AI Foundry Agent Service natively supports the Model Context Protocol as a tool, empowering your agents to leverage a wide array of external capabilities via standardized protocol endpoints.\n"
     ]
    }
   ],
   "source": [
    "# List all messages in the thread, printing assistant responses\n",
    "messages = project_client.agents.messages.list(\n",
    "    thread_id=thread.id, order=ListSortOrder.ASCENDING\n",
    ")\n",
    "for data_point in messages:\n",
    "    last_content = data_point.content[-1]\n",
    "    if isinstance(last_content, MessageTextContent):\n",
    "        print(f\"{data_point.role}: {last_content.text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17ac5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent, agent ID: asst_bkaLGyf7y6cf3jjID84QMPGe\n"
     ]
    }
   ],
   "source": [
    "# Clean up by deleting the agent\n",
    "project_client.agents.delete_agent(agent.id)\n",
    "print(f\"Deleted agent, agent ID: {agent.id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
